---
title: "STAT 545 Assignment B4"
author: "Thomas Deckers"
date: "13/11/2023"
output: github_document
---

```{R, echo = FALSE}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(janeaustenr))
suppressPackageStartupMessages(library(stopwords))
```

# STAT 545 Assignment B4 option A: Strings and Functional Programming

## Exercise 1: Word counts in Jane Austen


### Intro
For this exercise, we'd like to make a plot of the most common words appearing
in Jane Austen's *Emma*, exluding stopwords such as "the", "a", and
"and".

### Data
Let's inspect the data, provided by the `janeaustenr` package:

```{R}
typeof(emma)

head(emma, n = 16)
```

As we can see, we have a character array, where each entry is a line of the text.

Our other input is the list of stopwords from the `stopwords` package.

```{R}
stopwds <- stopwords("en")

typeof(stopwds)

head(stopwds)
```
This is stored in a very similar format.

### Proprocessing
First things first, we want to transform the format of emma into an array of 
individual words. 
This will require first removing the empty elements, and all the punctuation.

```{R}
my_emma <- emma %>%
  str_replace_all("[:punct:]|[:symbol:]|[:digit:]", " ") %>% # Remove punctuation, numbers, and symbols
  tolower() %>% # Remove all capitalization
  str_split(" ") %>% # Split on the words
  flatten() %>% # Remove the lines as they previously were
  unlist() # make it a character array

#lastly, remove the empty entries
my_emma <- my_emma[my_emma != ""] # Remove the blank lines

head(my_emma, n = 30)
```

Here, I replaced punctuation with spaces. This occasionally divides words which
are arguably a single word, such as "twenty-one", and "long-standing".
The easy alternative is to remove punctuation outright. However, this creates
the issue that words that are only separated by punctuation marks—most commonly
an emdash in this text—end up being treated as one word.
To deal with both of these issues would require a complicated context-dependent
algorithm, but for now I'll take the lesser of two evils.

### Counting and filtering
 Now we need to generate a count. Luckily, dplyr provides a convenient function
 for this. After this we can easily select based on the list of stopwords.
```{R}
emma_counts <- tibble("word" = my_emma) %>%
  count(word)

emma_counts <- emma_counts %>%
  filter(!word %in% stopwords("en")) %>%
  arrange(desc(n))

head(emma_counts, n = 10)
```
We can see a few things that are not great here.
"Mr," "Ms", "Mrs", "Miss", "Harriet", and "Emma" all come from addressing characters. This
doesn't really tell us much about Austen's word choice.
Then of course, "s" shows up from contractions where the apostrophe was replaced
with a space. Let's remove all of this as well, along with some more proper nouns
that turn up near the top.

```{R}
manual_word_blacklist <- c("mr", "s", "mrs", "miss", "harriet", "emma",
                           "weston", "knightley", "elton", "woodhouse", "jane",
                           "fairfax", "churchill", "hartfield", "frank")

emma_counts <- emma_counts %>%
  filter(!word %in% manual_word_blacklist)

head(emma_counts, n = 20)
```
There's another approximation that has to be made here. Emma contains a character
named "Frank". Presumably, a large share of the occurrences of the word "frank"
refers to this character as opposed to the English noun, so I am removing it
from the list. However, we do also lose any usage of the noun.
A more sophisticated approach might have used regex to match lower case occurences
of the word "frank", although this still would have missed instances that occur
at the start of the sentence.

### Plotting
The simplest way to view this is as a column plot of the top few words.

```{R}
emma_counts %>% head(n=20) %>%
  mutate(word = factor(word, levels = word)) %>%
  ggplot(aes(x=word, y=n)) +
  geom_col() +
  labs(x = "Word", y = "Number of Occurences")
```

## Exercise 2: Modified Pig Latin

Here, I will create a function that takes in a sentence, and turns it into a 
modified version of Pig Latin.
My version will have the following rules

1. Leave words with two letters or less unmodified
2. Move the last consonant and any trailing vowels to the start of the word
3. If a word starts and ends with the same consonant, add an o between the 
part now moved the front and the original start of the word
3. Add an "s" to the start of the word, if we haven't already moved an s to the start

I'll first define a helper function that takes only a single word of length
greater than 2, to do the heavy lifting.

```{R}
.piglatin_word <- function(word){
  
  # select the case of the s to add, based on the first letter of the word
  s_case <- ifelse(str_detect(word, "^[:upper:]"), "S","s")
  
  word <- tolower(word)
  
  suffix_loc <- str_locate(word, "[^a,e,i,o,u,y][a,e,i,o,u,y]*$") # Find the last consonant and trailing vowels
  suffix = str_sub(word,suffix_loc[1],suffix_loc[2])
  
  str_c(s_case,  # Add an s to the start of the word
        ifelse(suffix != "s", suffix, ""), # Add ending of the word, unless it's just s
        ifelse(str_detect(word, "^([^a,e,i,o,u,y]).*\\1$"),"o", ""), # If it starts and end with the same letter, add an o in between
        str_sub(word,0,suffix_loc[1]-1)) # And finally add the rest of the word
}
```

```{R}
my_piglatin <- function(text) {
    str_split_1(text, " |[:punct:]") %>%
    map_if(\(x) (str_length(x) > 2), ~ .piglatin_word(.x)) %>%
    unlist
}
```

```{R}
my_piglatin <- function(text) {
  str_replace_all(text,"([:alpha:]{3,})", .piglatin_word)
}
```

```{R}
my_piglatin("hi hello")
#str_split("Hello! hi everyone.", "[:punct:]")
str_locate("testeee", "[^a,e,i,o,u,y][a,e,i,o,u,y]*$")[1
                                                       ]

.piglatin_word("caught")

my_piglatin("This is my abba test cool sentence")
```

TODO: Roxygen, including examples

TODO: check inputs
note: can't take newlines

TODO: write tests
